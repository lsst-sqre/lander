\section{Introduction}
The Large Synoptic Survey Telescope (\gls{LSST}) will usher in a new era of data-intensive astronomy. The observing program will observe the southern sky repeatedly over 10 years in 6 bands providing an unprecedented census of the astrophysical bodies in the universe.  Funded by the \gls{NSF} and the \gls{DOE}, this keystone observatory is due to go into operations in October 2022.

Producing 20TB of data a night, this is a huge step up in data acquisition from other optical telescopes. At its conception this was considered an ominous data volume requiring highly specialized computing infrastructure. In the intervening time, however, the growth of planetary-scale industry services (such us Goggle or Facebook) has resulted in software, engineering techniques and infrastructure that render this sort of data flow routine. \gls{LSST}  operations are expected to cost tens of millions a year with order of \$10M computing budget.

The \gls{LSST} computing load is a poster child for cloud computing - the science platform is designed for kubernetes and the
data release processing fits perfectly with opportunistic compute pricing. This is a large \gls{NSF} project and the the one most suited and ready for cloud deployment.
We have used some pathfinder deployments to demonstrate that it is feasible to use commercial cloud providers for the \gls{LSST} \gls{Data Management} production system. Such a move would bring significant technological and operational advantages; the barrier to acting on this is price and uncertainty on future pricing.

A solution might be to reach a fixed price partnership for a cloud-based deployment of the \gls{Data Management} systems in which Google undertake to provide \emph{do what is needed} for success at some reasonable and agreed-upon annual fee.

\input{today}
\input{need}
\input{cost}

\input{conclusion}
